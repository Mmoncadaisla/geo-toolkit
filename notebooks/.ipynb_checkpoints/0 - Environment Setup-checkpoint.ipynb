{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6><b>\n",
    "    \n",
    "Environment setup Notebook\n",
    "\n",
    "</b></font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "This test has been ran using [Python](https://www.python.org/) together with a [PostgreSQL 12](https://www.postgresql.org/) + [PostGIS 3](https://postgis.net/) database for geospatial analytics.\n",
    "\n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "For this reason, and in order to be able to mimic the environment, a [docker-compose](https://docs.docker.com/compose/) set-up has been prepared, see more information in the Readme file in the main repo directory.\n",
    "\n",
    "The main goal of this Notebook is to recreate the database tables created throughout the process and, if desired, run the process on your own.\n",
    "\n",
    ">**NOTE:** Run this Notebook only if you'd want to recreate the database tables created and after setting up the docker environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why this setup?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "This setup has been chosen for three main reasons,\n",
    "    \n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "- Geospatial manipulations\n",
    "\n",
    "<p></p><p></p><p></p>\n",
    "    \n",
    "- Out of memory capacity\n",
    "    \n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "- Familiarity\n",
    "    \n",
    "<p></p><p></p><p></p>\n",
    "    \n",
    "<font size=3>\n",
    "\n",
    "This test has been run using a 8 GB RAM 4 core laptop with only OS software and no economical cost (besides data adquisition which has been obtained through a CARTO non-free plan for unavailability reasons).\n",
    "    \n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "The strong need of performing potentially out of memory operations plus geospatial processes have pushed me to find what I believe was the right toolset for this purpose.\n",
    "    \n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "For this reason, I've chosen to use a combination of the following,\n",
    "    \n",
    "1. [**Python**](https://www.python.org/), IMHO one of the most popular DS programming languages with a large variety of packages for this purpose (although not the most efficient)\n",
    "\n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "    \n",
    "2. [**PostgreSQL**](https://www.postgresql.org/), an open source object-relational database system with over 30 years of active development according to the official docs\n",
    "    \n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "    \n",
    "3. [**PostGIS**](https://postgis.net/), a geospatial extension of the prior with support for a large amount of different geospatial operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the .sql file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "The first step we'll take will be to download the `.sql` file generated by [pg_dump](https://www.postgresql.org/docs/12/app-pgdump.html) from Google Drive. \n",
    "\n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "To do so we'll use `gdown` (see more information [here](https://pypi.org/project/gdown/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gdown and set the url to the download link (with confirmation for file size)\n",
    "\n",
    "import gdown\n",
    "\n",
    "url = \"https://drive.google.com/u/1/uc?export=download&confirm=ZM_Z&id=1zRK5VIf1KOxeRv0f7gOiAPstHRghA6CS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/u/1/uc?export=download&confirm=ZM_Z&id=1zRK5VIf1KOxeRv0f7gOiAPstHRghA6CS\n",
      "To: /notebooks/database.sql.gz\n",
      "1.51GB [01:35, 15.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'database.sql.gz'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the compressed file through the download function and save it to a .sql.gz file - this might take a while\n",
    "\n",
    "gdown.download(url, output='database.sql.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncompress the downloaded file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "We'll be accessing the terminal directly from the Jupyter Notebook, using `!` for this purpose. \n",
    "\n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "In this case, we'll use `gzip` with `-d` flag to unzip the file. The resulting file will be a `.sql` file of around 6 gb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d database.sql.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate the database tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "We're going to recreate the database tables by following the next steps,\n",
    "\n",
    "<p>\n",
    "\n",
    "</p>\n",
    "\n",
    "- **Create role:** Create the corresponding role with [CREATE ROLE statement](https://www.postgresql.org/docs/12/sql-createrole.html)\n",
    "<p>\n",
    "\n",
    "</p>\n",
    "\n",
    "- **Run the .sql file:** Run the .sql file. This will create the corresponding schema, tables, copy the data and add the corresponding indexes\n",
    "<p>\n",
    "\n",
    "</p>\n",
    "\n",
    "- **Set search path:** Set the search path (optional) so that mmoncada schema tables appear when exploring tables through psql\n",
    "<p>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:  role \"mmoncada\" already exists\r\n"
     ]
    }
   ],
   "source": [
    "!PGPASSWORD=postgres psql -h postgres -U postgres -c \"CREATE ROLE mmoncada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET\n",
      "SET\n",
      "SET\n",
      "SET\n",
      "SET\n",
      " set_config \n",
      "------------\n",
      " \n",
      "(1 row)\n",
      "\n",
      "SET\n",
      "SET\n",
      "SET\n",
      "SET\n",
      "CREATE SCHEMA\n",
      "ALTER SCHEMA\n",
      "SET\n",
      "SET\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "CREATE SEQUENCE\n",
      "ALTER TABLE\n",
      "ALTER SEQUENCE\n",
      "CREATE TABLE\n",
      "ALTER TABLE\n",
      "ALTER TABLE\n",
      "COPY 220134\n",
      "COPY 219734\n",
      "COPY 5\n",
      "COPY 37383484\n",
      "COPY 9386\n",
      "  setval  \n",
      "----------\n",
      " 37383484\n",
      "(1 row)\n",
      "\n",
      "ALTER TABLE\n",
      "ALTER TABLE\n",
      "CREATE INDEX\n",
      "CREATE INDEX\n",
      "CREATE INDEX\n",
      "CREATE INDEX\n"
     ]
    }
   ],
   "source": [
    "!PGPASSWORD=postgres psql -h postgres -U postgres -f database.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET\r\n"
     ]
    }
   ],
   "source": [
    "!PGPASSWORD=postgres psql -h postgres -U postgres -c \"SET search_path to 'mmoncada'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4><b>\n",
    "    \n",
    "What's next? \n",
    "\n",
    "</b>\n",
    "\n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "\n",
    "Access the next Notebook, [`1 - CARTO data to Postgres`](1%20-%20CARTO%20data%20to%20Postgres.ipynb)\n",
    "\n",
    "</font> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
